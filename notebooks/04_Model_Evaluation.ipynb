# 04_Model_Evaluation.ipynb

# --- Import Libraries ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score
import joblib

# --- Load Test Data ---
# Make sure test.csv is available (Kaggle Titanic format)

test_df = pd.read_csv("test.csv")
train_df = pd.read_csv("train.csv")  # Needed to align preprocessing

# --- Load Best Model ---
best_model = joblib.load("best_titanic_model.pkl")

# --- Prepare Test Data ---
# The model pipeline includes preprocessing, so we just need same feature columns

X_test = test_df.drop(columns=["PassengerId", "Name", "Ticket", "Cabin"])

# Handle missing values (Age, Fare, Embarked) - same as train preprocessing
X_test["Age"] = X_test["Age"].fillna(train_df["Age"].median())
X_test["Fare"] = X_test["Fare"].fillna(train_df["Fare"].median())
X_test["Embarked"] = X_test["Embarked"].fillna(train_df["Embarked"].mode()[0])

# ⚠️ Note: Titanic Kaggle `test.csv` doesn’t include `Survived` column.
# For evaluation, you would need actual labels (only available via competition submission).
# Here, we assume we have a file `gender_submission.csv` as ground truth.

y_true = pd.read_csv("gender_submission.csv")["Survived"]  # Ground truth labels

# --- Predictions ---
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:,1]

# --- Confusion Matrix ---
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Not Survived","Survived"], yticklabels=["Not Survived","Survived"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# --- Classification Report ---
print("Classification Report:")
print(classification_report(y_true, y_pred))

# --- ROC Curve ---
fpr, tpr, _ = roc_curve(y_true, y_prob)
auc = roc_auc_score(y_true, y_prob)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {auc:.2f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Titanic Survival Prediction")
plt.legend()
plt.show()

# --- Document Results ---
print("Model Evaluation Summary:")
print(f"ROC-AUC Score: {auc:.3f}")

